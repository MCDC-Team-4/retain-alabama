{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Install packages\n",
    "\n",
    "First thing is to install pandas, numpy, scikit-learn, matplotlib, and seaborn. Then below you see where we import the packages in our notebook."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, ElasticNet, Lasso\n",
    "from sklearn.metrics import classification_report, mean_squared_error, confusion_matrix, plot_confusion_matrix, accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# allow multiple outputs per cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import the data and start exploring it"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "data = pd.read_csv('../Project Retain Alabama/Survey Data and Info/UABformatChange.csv')\n",
    "alabamaData = pd.read_csv('../Project Retain Alabama/Survey Data and Info/alabamaData.csv')\n",
    "alabamaData.describe()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some commands you could start with : \n",
    "- data.describe()\n",
    "- data.shape\n",
    "- data.isnull().sum()\n",
    "- data['column name'].value_counts()"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transform the Data for Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = data.replace(np.NAN, 0)\n",
    "alabamaData = alabamaData.replace(np.NAN, 0)\n",
    "data = data.loc[:,~data.columns.duplicated()]\n",
    "alabamaData = alabamaData.loc[:,~alabamaData.columns.duplicated()]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Use get dummies for one hot encoding \n",
    "# pd.get_dummies(data.University, prefix='University Code')\n",
    "readData = pd.get_dummies(data, columns=['Race','StateHS','Major','Major Code', 'Major Code Revised'])\n",
    "readAlabamaData = pd.get_dummies(alabamaData, columns=['Race','StateHS','Major','Major Code', 'Major Code Revised'])\n",
    "\n",
    "readData\n",
    "readAlabamaData.describe()\n",
    "# data = pd.concat([data, rd], axis=1)\n",
    "# data\n",
    "# print(data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "readData['StayAL'].value_counts()\n",
    "alabamaData['StayAL'].value_counts()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# A useful function for changing strings \n",
    "# for i in list(data.columns):\n",
    "#     data[i] = data[i].apply(lambda x: str(x)).apply(lambda x: x.replace('|' , ','))\n",
    "# data = data[~data.columns.duplicated()]\n",
    "alabamaData.describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# renaming columns\r\n",
    "pd.options.display.max_columns = 300\r\n",
    "pd.options.display.max_rows = 10\r\n",
    "# readData\r\n",
    "readAlabamaData\r\n",
    "# data = data.rename(columns = {'_Virginia': 'Virginia'})\r\n",
    "# data\r\n",
    "# Regressiona"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# lstToKeep = [0,1]\n",
    "readAlabamaData = readAlabamaData[readAlabamaData.StayAL != 3]\n",
    "\n",
    "# Use multiple x values, especially ones that are dummies\n",
    "# get rid of ALHS.1 'don't know'\n",
    "# Split the dataset into two different ones, \n",
    "x = readAlabamaData['ALHS.1'].values.reshape(-1,1) \n",
    "print(x) #original is 8208 rows\n",
    "print('mdddd')\n",
    "y = readAlabamaData['StayAL'].values.reshape(-1,1)\n",
    "print(y) #1206 rows \n",
    "# fix above this line. \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "model = LogisticRegression(solver='liblinear', random_state=0)\n",
    "model.fit(X_train,y_train)\n",
    "model.classes_\n",
    "# print('Hoping for the best')\n",
    "# model.predict_proba(y)\n",
    "print('Hoping for the best x')\n",
    "model.predict_proba(x)\n",
    "print('The other bad boy')\n",
    "y_predicted = model.predict(X_test)\n",
    "\n",
    "# print('Holy moly')\n",
    "# model.predict(y)\n",
    "print('Lets get funky')\n",
    "\n",
    "print('train')\n",
    "# X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "# sc = StandardScaler()\n",
    "\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# X_test = sc.transform(X_test)\n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators=20, random_state=0)\n",
    "regressor.fit(x, y)\n",
    "plt.scatter(x,y)\n",
    "plt.plot(y, regressor.predict(x),\n",
    "         color = 'green')\n",
    "# Y_pred = regressor.predict(X_train) # test the output by changing values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# confusion_matrix(y_test,y_pred)\n",
    "# classification_report(y_test,y_pred)\n",
    "# accuracy_score(y_test, y_pred)\n",
    "\n",
    "# lin_reg = LinearRegression()\n",
    "# lin_reg.fit(x, y)\n",
    "# lin_reg.intercept_, lin_reg.coef_\n",
    "# prayingToGod = lin_reg.predict(y)\n",
    "\n",
    "\n",
    "# # \n",
    "# plt.scatter(x,y)\n",
    "# plt.plot(x,prayingToGod,color='blue')\n",
    "# plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# to make this notebook's output stable across runs\r\n",
    "np.random.seed(42)\r\n",
    "\r\n",
    "# To plot pretty figures\r\n",
    "%matplotlib inline\r\n",
    "import matplotlib as mpl\r\n",
    "mpl.rc('axes', labelsize=14)\r\n",
    "mpl.rc('xtick', labelsize=12)\r\n",
    "mpl.rc('ytick', labelsize=12)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Validation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "interpreter": {
   "hash": "7c660e012d33f79d07e1d39cd07c4f538d8019c99abffdbb11ac0ff4d8912368"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}